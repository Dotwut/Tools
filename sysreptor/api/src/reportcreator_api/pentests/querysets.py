import functools
import io
import json
import operator
import random
import copy
import secrets
import tempfile
import uuid
from base64 import b64encode, b64decode
from django.conf import settings
from django.db import models, transaction
from django.db.models.functions import Coalesce
from django.core.exceptions import ValidationError
from reportcreator_api.archive import crypto
from reportcreator_api.archive.crypto.base import ReadIntoAdapter
from reportcreator_api.archive.crypto.secret_sharing import ShamirLarge
from reportcreator_api.archive.crypto.storage import EncryptedFileAdapter, IterableToFileAdapter

from reportcreator_api.pentests.customfields.predefined_fields import FINDING_FIELDS_CORE, FINDING_FIELDS_PREDEFINED
from reportcreator_api.pentests.customfields.types import FieldOrigin, parse_field_definition
from reportcreator_api.users.models import PentestUser
from reportcreator_api.utils.files import normalize_filename
from reportcreator_api.utils.utils import groupby_to_dict, omit_keys
from reportcreator_api.archive.crypto import pgp


class ProjectTypeQueryset(models.QuerySet):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        pt_filters = models.Q(models.Q(linked_project=None) & models.Q(linked_user=None)) | \
            models.Q(linked_project__members__user=user)
        if settings.ENABLE_PRIVATE_DESIGNS:
            pt_filters |= models.Q(linked_user=user)
        return self.filter(pt_filters)

    def custom_finding_field_definitions(self):
        """
        Return all custom field definitions over all globally visible ProjectTypes.
        Handle conflicting data types of custom fields by using the field of the first ProjectType
        e.g. ProjectType1 defines custom_field: string; ProjectType2 defines custom_field: list[string] => use custom_field: string
        """
        all_finding_field_definitions = self \
            .filter(linked_project=None) \
            .order_by('-created', 'id') \
            .values_list('finding_fields', flat=True)
        return parse_field_definition(functools.reduce(
            operator.or_, 
            map(lambda fd: dict(filter(lambda t: t[1].get('origin') == FieldOrigin.CUSTOM.value, fd.items())), all_finding_field_definitions),
            {}
        ))


class ProjectTypeManager(models.Manager.from_queryset(ProjectTypeQueryset)):
    use_in_migrations = True

    @transaction.atomic()
    def copy(self, instance, **kwargs):
        from reportcreator_api.pentests.models import UploadedAsset

        assets = list(instance.assets.all())

        # Copy model
        instance = copy.copy(instance)
        for k, v in (kwargs or {}).items():
            setattr(instance, k, v)
        instance.pk = None
        instance.lock_info_data = None
        instance.save()

        # Copy all assets
        for a in assets:
            a.pk = None
            a.linked_object = instance
        UploadedAsset.objects.bulk_create(assets)

        return instance


class PentestProjectQueryset(models.QuerySet):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(members__user=user)


class PentestProjectManager(models.Manager.from_queryset(PentestProjectQueryset)):
    @transaction.atomic()
    def copy(self, instance, **kwargs):
        from reportcreator_api.pentests.models import PentestFinding, ReportSection, NotebookPage, UploadedImage, UploadedProjectFile, SourceEnum, ProjectMemberInfo

        findings = list(instance.findings.all())
        sections = list(instance.sections.all())
        notes = list(instance.notes.select_related('parent').all())
        members = list(instance.members.all())
        images = list(instance.images.all())
        files = list(instance.files.all())

        # Copy project
        instance = copy.copy(instance)
        for k, v in (kwargs or {}).items():
            setattr(instance, k, v)
        instance.pk = None
        instance.readonly = False
        instance.lock_info_data = None
        instance.project_type = instance.project_type.copy(
            linked_user=None,
            source=SourceEnum.SNAPSHOT if instance.project_type.source not in [SourceEnum.IMPORTED_DEPENDENCY, SourceEnum.CUSTOMIZED] else instance.project_type.source)
        instance.save()
        instance.project_type.linked_project = instance
        instance.project_type.save(update_fields=['linked_project'])

        for mi in members:
            mi.pk = None
            mi.project = instance
        ProjectMemberInfo.objects.bulk_create(members)

        # Copy sections
        ReportSection.objects.filter(project=instance).delete()
        for s in sections:
            s.pk = None
            s.project = instance
        ReportSection.objects.bulk_create(sections)

        # Copy findings
        for f in findings:
            f.pk = None
            f.project = instance
        PentestFinding.objects.bulk_create(findings)

        # Copy notes
        for n in notes:
            n.pk = None
            n.project = instance
        NotebookPage.objects.bulk_create(notes)
        # Update parent to copied model
        for n in notes:
            if n.parent:
                n.parent = next(filter(lambda pn: pn.note_id == n.parent.note_id, notes), None)
        NotebookPage.objects.bulk_update(notes, ['parent'])

        # Copy images
        for i in images:
            i.pk = None
            i.linked_object = instance
        UploadedImage.objects.bulk_create(images)

        # Copy files
        for f in files:
            f.pk = None
            f.linked_object = instance
        UploadedProjectFile.objects.bulk_create(files)

        return instance
    
    @transaction.atomic
    def set_members(self, instance, members):
        from reportcreator_api.pentests.models import ProjectMemberInfo

        if members is None:
            return

        for m in members:
            m.pk = None
            m.project = instance
            m.roles = list(set(m.roles))
        
        members_map = dict(map(lambda m: (m.user_id, m), members))
        existing_members_map = dict(map(lambda m: (m.user_id, m), instance.members.all()))

        if new_members := omit_keys(members_map, existing_members_map.keys()).values():
            ProjectMemberInfo.objects.bulk_create(new_members)
        if removed_members := omit_keys(existing_members_map, members_map.keys()).values():
            ProjectMemberInfo.objects.filter(id__in=[m.pk for m in removed_members]).delete()

        updated_members = []
        for k, m in existing_members_map.items():
            if k in members_map and set(m.roles) != set(members_map[k].roles):
                m.roles = members_map[k].roles
                updated_members.append(m)
        if updated_members:
            ProjectMemberInfo.objects.bulk_update(updated_members, ['roles'])

    def add_member(self, user, projects):
        from reportcreator_api.pentests.models import ProjectMemberInfo

        existing_members = set(ProjectMemberInfo.objects \
            .filter(project__in=projects) \
            .filter(user=user) \
            .values_list('project_id', flat=True))
        new_members = [ProjectMemberInfo(user=user, project=p) for p in projects if p.id not in existing_members]
        ProjectMemberInfo.objects.bulk_create(new_members)


class PentestFindingQueryset(models.QuerySet):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(project__members__user=user)


class ReportSectionQueryset(models.QuerySet):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(project__members__user=user)


class FindingTemplateQueryset(models.QuerySet):
    def increment_usage_count(self, by=1):
        return self.update(usage_count=models.F('usage_count') + models.Value(by))

    def get_field_definition(self):
        from reportcreator_api.pentests.models import ProjectType
        return FINDING_FIELDS_CORE | FINDING_FIELDS_PREDEFINED | \
               ProjectType.objects.custom_finding_field_definitions() | \
               FINDING_FIELDS_PREDEFINED | FINDING_FIELDS_CORE


class NotebookPageQuerySet(models.QuerySet):
    pass


class NotebookPageManager(models.Manager.from_queryset(NotebookPageQuerySet)):
    def create(self, project=None, user=None, order=None, parent=None, **kwargs):
        from reportcreator_api.pentests.models import NotebookPage

        if not order and (project or user):
            if project:
                order_qs = NotebookPage.objects.filter(project=project)
            elif user:
                order_qs = NotebookPage.objects.filter(user=user)
            order = Coalesce(
                models.Subquery(
                    order_qs
                    .filter(parent=parent)
                    .values('parent')
                    .annotate(max_order=models.Max('order'))
                    .values_list('max_order')),
                models.Value(0)
            ) + models.Value(1)
        
        obj = super().create(project=project, user=user, parent=parent, order=order, **kwargs)
        obj.refresh_from_db()
        return obj
    
    def check_parent_and_order(self, instances, missing_instances=None):
        # * Update order values: first all notes in data, then missing notes (keep order of missing notes, but move to end)
        # * and validate no circular dependencies: beginning from the tree root, every note must be in the tree. 
        #   If it does not have a path from root to node, there is a circular dependency.
        missing_instances = missing_instances or []
        parent_dict = groupby_to_dict(instances, key=lambda n: n.parent_id or uuid.UUID(int=0))
        in_tree = set()
        def to_tree(parent_id):
            layer = parent_dict.get(parent_id, [])
            layer_sorted = sorted(filter(lambda n: n not in missing_instances, layer), key=lambda n: n.order) + \
                sorted(filter(lambda n: n in missing_instances, layer), key=lambda n: n.order)
            for idx, n in enumerate(layer_sorted):
                n.order = idx + 1
                in_tree.add(n)
                to_tree(n.id)
        to_tree(uuid.UUID(int=0))
        if len(in_tree) != len(instances):
            raise ValidationError('Circular parent relationships detected')


class UserPublicKeyQuerySet(models.QuerySet):
    def only_enabled(self):
        return self.filter(enabled=True)


class UserPublicKeyManager(models.Manager.from_queryset(UserPublicKeyQuerySet)):
    def create(self, public_key=None, public_key_info=None, **kwargs):
        if not public_key_info and public_key:
            public_key_info = pgp.public_key_info(public_key)
        return super().create(public_key=public_key, public_key_info=public_key_info, **kwargs)


class ArchivedProjectQuerySet(models.QuerySet):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(key_parts__user=user)


class ArchivedProjectManager(models.Manager.from_queryset(ArchivedProjectQuerySet)):
    def get_possible_archive_users_for_project(self, project):
        from reportcreator_api.pentests.models import UserPublicKey
        return PentestUser.objects \
            .filter(models.Q(is_global_archiver=True) | models.Q(pk__in=project.members.values_list('user_id'))) \
            .prefetch_related(models.Prefetch('public_keys', UserPublicKey.objects.only_enabled()))

    def get_archive_users_for_project(self, project):
        return self.get_possible_archive_users_for_project(project) \
            .only_active() \
            .only_with_public_keys() \
            

    @transaction.atomic()
    def create_from_project(self, project, name=None, users=None, delete_project=True):
        from reportcreator_api.pentests.models import ArchivedProject, ArchivedProjectKeyPart, ArchivedProjectPublicKeyEncryptedKeyPart

        name = name or project.name
        users = list(users or self.get_archive_users_for_project(project))
        if len(users) < settings.ARCHIVING_THRESHOLD:
            raise ValueError('Too few users')

        archive = ArchivedProject(
            name=name or project.name,
            threshold=settings.ARCHIVING_THRESHOLD,
        )
        key_parts_to_create = []
        encrypted_key_parts_to_create = []

        # Create a random AES-256 key for encrypting the whole archive
        aes_key = secrets.token_bytes(32)
        # Split the AES key using shamir secret sharing and distribute key parts to users
        shamir_key_parts = ShamirLarge.split_large(k=archive.threshold, n=len(users), secret=aes_key)
        for user, (shamir_key_id, shamir_key) in zip(users, shamir_key_parts):
            # Encrypt the per-user shamir key with a per-user AES key
            # This is mainly used for integrity protection to detect corrupted/user-forged shamir key parts.
            # This additional encryption layer makes it possible to other public key encryptions 
            # other than PGP (which uses its own file encryption layer on top of public keys) in the future.
            user_aes_key = secrets.token_bytes(32)
            shamir_key_part_data_io = io.BytesIO()
            with crypto.open(shamir_key_part_data_io, mode='wb', key=crypto.EncryptionKey(id=None, key=user_aes_key)) as c:
                c.write(json.dumps({'key_id': shamir_key_id, 'key': b64encode(shamir_key).decode()}).encode())

            key_part_model = ArchivedProjectKeyPart(
                archived_project=archive, 
                user=user,
                encrypted_key_part=shamir_key_part_data_io.getvalue()
            )
            key_parts_to_create.append(key_part_model)

            # Encrypt the per-user AES key with each user's public key
            user_public_keys = [pk for pk in user.public_keys.all() if pk.enabled]
            if not user_public_keys:
                raise ValueError('User does not have any usable public key')
            for public_key in user_public_keys:
                encrypted_key_parts_to_create.append(ArchivedProjectPublicKeyEncryptedKeyPart(
                    key_part=key_part_model,
                    public_key=public_key,
                    encrypted_data=public_key.encrypt(data=b64encode(user_aes_key) + b'\n')
                ))

        # export archive and encrypt with AES-256 key and upload to storage
        from reportcreator_api.archive.import_export import export_projects
        archive.file = EncryptedFileAdapter(
            file=IterableToFileAdapter(export_projects([project], export_all=True), name=str(uuid.uuid4())),
            key=crypto.EncryptionKey(id=None, key=aes_key)
        )

        # Create models in DB
        archive.save()
        ArchivedProjectKeyPart.objects.bulk_create(key_parts_to_create)
        ArchivedProjectPublicKeyEncryptedKeyPart.objects.bulk_create(encrypted_key_parts_to_create)

        # Delete project
        if delete_project:
            project.delete()

        return archive
    
    @transaction.atomic()
    def restore_project(self, archive):
        from reportcreator_api.pentests.models import PentestProject
        from reportcreator_api.archive.import_export.import_export import import_projects

        # Combine key parts with shamir secret sharing to decrypt the archive key
        key_parts = list(filter(lambda k: k.is_decrypted, archive.key_parts.all()))
        if len(key_parts) < archive.threshold:
            raise ValueError('Too few key parts available')
        archive_key = ShamirLarge.combine_large([(k.key_part['key_id'], b64decode(k.key_part['key'])) for k in key_parts])

        # Decrypt archive and import project
        with tempfile.SpooledTemporaryFile(max_size=settings.FILE_UPLOAD_MAX_MEMORY_SIZE, mode='w+b') as f:
            with crypto.open(archive.file, mode='rb', key=crypto.EncryptionKey(id=None, key=archive_key)) as c:
                while chunk := c.read(settings.FILE_UPLOAD_MAX_MEMORY_SIZE):
                    f.write(chunk)
            f.seek(0)
            projects = import_projects(f)
        
        # Add archivers as members (only relevant for global archivers)
        for k in archive.key_parts.all():
            PentestProject.objects.add_member(k.user, projects)

        # Delete archive
        archive.delete()
        return projects[0]


class UploadedFileQueryset(models.QuerySet):
    def filter_name(self, name):
        from reportcreator_api.pentests.models import UploadedFileBase
        return self.filter(name_hash=UploadedFileBase.hash_name(name))


class UploadedImageQueryset(UploadedFileQueryset):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(linked_object__members__user=user)


class UploadedUserNotebookImageQueryset(UploadedFileQueryset):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(linked_object=user)


class UploadedAssetQueryset(UploadedFileQueryset):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(models.Q(linked_object__linked_project=None) | models.Q(linked_object__linked_project__members__user=user))


class UploadedProjectFileQueryset(UploadedFileQueryset):
    def only_permitted(self, user):
        if user.is_admin:
            return self
        return self.filter(linked_object__members__user=user)


class UploadedFileManagerMixin:
    def create(self, file, linked_object, name=None, **kwargs):
        # Change name when a file with the same name already exists
        name = normalize_filename(name or file.name or 'file')
        while self.filter(linked_object=linked_object).filter_name(name).exists():
            if (ext_idx := name.rfind('.')) and ext_idx != -1:
                name = name[:ext_idx] + '-' + str(random.randint(1, 1000000)) + name[ext_idx:]

        # Randomize filename in storage to not leak information
        return super().create(file=file, name=name, linked_object=linked_object, **kwargs)


class UploadedImageManager(UploadedFileManagerMixin, models.Manager.from_queryset(UploadedImageQueryset)):
    pass


class UploadedAssetManager(UploadedFileManagerMixin, models.Manager.from_queryset(UploadedAssetQueryset)):
    pass


class UploadedUserNotebookImageManager(UploadedFileManagerMixin, models.Manager.from_queryset(UploadedUserNotebookImageQueryset)):
    pass


class UploadedProjectFileManager(UploadedFileManagerMixin, models.Manager.from_queryset(UploadedProjectFileQueryset)):
    pass

