import elasticapm
from datetime import timedelta
from django.utils import timezone
from django.db.models import Q, F, Prefetch, Exists, OuterRef, Subquery, Max

from reportcreator_api.pentests.models import NotebookPage, UploadedImage, UploadedProjectFile, UploadedUserNotebookImage, PentestProject
from reportcreator_api.users.models import PentestUser


def is_referenced_in_project(project, f):
    # Project data (sections)
    if f.name in str(project.data_all):
        return True
    
    # Findings
    for finding in project.findings.all():
        if f.name in str(finding.data_all):
            return True
    
    # Notes
    for note in project.notes.all():
        if f.name in note.text or f.name in note.title:
            return True
    return False


@elasticapm.async_capture_span()
async def cleanup_project_files(task_info):
    # Only cleanup older files, to prevent race conditions: upload -> cleanup -> save text with reference -> referenced file already deleted
    older_than = timezone.now() - timedelta(days=2)
    projects = PentestProject.objects \
        .filter(created__lt=older_than) \
        .select_related('project_type') \
        .prefetch_related(
            'findings', 
            'notes', 
            Prefetch('images', UploadedImage.objects.filter(updated__lt=older_than), to_attr='images_cleanup'),
            Prefetch('files', UploadedProjectFile.objects.filter(updated__lt=older_than), to_attr='files_cleanup'),
        )
    # Only check projects that changed since the last cleanup
    if last_run := task_info['model'].last_success:    
        projects = projects.filter(
            Q(updated__gt=last_run) | 
            Q(findings__updated__gt=last_run) | 
            Q(sections__updated__gt=last_run) | 
            Q(notes__updated__gt=last_run)
        )
    projects = projects.distinct()
    
    # Check if files are referenced
    # Requires checking in python because of DB encryption
    cleanup_images = []
    cleanup_files = []
    async for p in projects:
        for f in p.images_cleanup:
            if not is_referenced_in_project(p, f):
                cleanup_images.append(f)
        for f in p.files_cleanup:
            if not is_referenced_in_project(p, f):
                cleanup_files.append(f)

    if cleanup_images:
        await UploadedImage.objects \
            .filter(pk__in=map(lambda f: f.pk, cleanup_images)) \
            .adelete()
    if cleanup_files:
        await UploadedProjectFile.objects \
            .filter(pk__in=map(lambda f: f.pk, cleanup_files)) \
            .adelete()


@elasticapm.async_capture_span()
async def cleanup_usernotebook_files(task_info):
    older_than = timezone.now() - timedelta(days=2)

    user_notes = NotebookPage.objects \
        .filter(user=OuterRef('pk'))
    if last_run := task_info['model'].last_success:
        user_notes = user_notes.filter(updated__gt=last_run)
    
    images_cleanup = UploadedUserNotebookImage.objects.filter(updated__lt=older_than)

    users = PentestUser.objects \
        .filter(created__lt=older_than) \
        .annotate(has_notes=Exists(user_notes)) \
        .annotate(has_images=Exists(images_cleanup.filter(linked_object=OuterRef('pk')))) \
        .filter(has_notes=True) \
        .filter(has_images=True) \
        .prefetch_related(
            'notes',
            Prefetch('images', images_cleanup, to_attr='images_cleanup'),
        )
    
    cleanup_images = []
    async for u in users:
        for f in u.images_cleanup:
            for n in u.notes.all():
                if f.name in n.text or f.name in n.title:
                    break
            else:
                cleanup_images.append(f)

    if cleanup_images:
        await UploadedUserNotebookImage.objects \
            .filter(pk__in=map(lambda f: f.pk, cleanup_images)) \
            .adelete()


async def cleanup_unreferenced_images_and_files(task_info):
    await cleanup_project_files(task_info)
    await cleanup_usernotebook_files(task_info)


def reset_stale_archive_restores(task_info):
    """
    Deletes decrypted shamir keys from the database, when archive restore is stale (last decryption more than 3 days ago),
    i.e. some users decrypted their key parts, but some are still missing.
    Prevent decrypted shamir keys being stored in the DB forever.
    """
    from reportcreator_api.pentests.models import ArchivedProject, ArchivedProjectKeyPart

    ArchivedProjectKeyPart.objects \
        .filter(decrypted_at__isnull=False) \
        .annotate(last_decrypted=Subquery(
            ArchivedProjectKeyPart.objects
            .filter(archived_project=OuterRef('archived_project'))
            .values('archived_project')
            .annotate(last_decrypted=Max('decrypted_at'))
            .values_list('last_decrypted')
        )) \
        .filter(last_decrypted__lt=timezone.now() - timedelta(days=3)) \
        .update(decrypted_at=None, key_part=None)
